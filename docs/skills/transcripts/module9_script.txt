Module 9: Rapid Evidence Review


Welcome! In our last module we learned how to channel collective intelligence for public good, including collaboration, co-creation, and open innovation to come up with solutions to problems.

But coming up with new solutions is not enough. As Bill Clinton famously said, "Nearly every problem has been solved by someone, somewhere. The challenge of the 21st century is to find out what works and scale it up. Today, we will discuss how to research what else is out there and how to do so efficiently in this module on Rapid Evidence Review.

Lets start with a story. In 2016, California State Senator Anthony Portantino read an LA Times opinion piece that advocated for a later start to the school day , arguing that starting later would increase teenagers sleep thereby reducing absences, increasing grades and test scores, decreasing student injuries, and reducing drowsy driving accidents. 
The article inspired Portantino to sponsor a bill, which was signed into law in 2019, requiring high schools to start after 8:30 am and middle schools no earlier than 8 am by the year 2022.
But Portantino came across the evidence by chance, while reading the newspaper. What if he had never seen the article? Or that he had read a slapdash article, full of opinion but no good solid evidence?
Good research is essential to the work of the public entrepreneur. Before championing an intervention such as later school start times, you need to know will the results be worth the investment it will take to bring about this change? 
While private sector entrepreneurs want to invent the newest app or product, public problem solvers want practical, tested solutions that contain less risk. 
Good evidence is the cornerstone of public problem solving. 
That's why, at this end of this module, you know three things:
1.How to find what possible solutions exist
2.How to evaluate whether a solution worked there," 
3.How to determine whether what worked "there" will also work "here," in our context and community. 
However, public entrepreneurs risk drowning in information. We can spend too much time reviewing one promising source or chasing one expert interview, not realizing there is better information elsewhere. This is why it is vital to have a strategy for allocating time appropriately and pragmatically to potential sources both from the academy and from social innovators, a strategy for efficiently gathering evidence of what works. 
We start by discussing academic research, focusing on randomized controlled trials - or RCTs - because they are particularly valued in the world of evidence-based policymaking. 
Why is that? If we want to know whether a policy or program has an effect on people's lives, we ideally compare what happens when a person receives the program and what happens when they do not receive it. 
A randomized study helps us ensure that two groups being compared are alike in all ways except for an intervention.
In an RCT, one group of individuals (called the treatment group) receives an intervention and the other (the control group) does not. People are randomly assigned into one of the two groups and, ideally, neither participants nor researchers know who is in which group. 
For example, in Tennessee an RCT was used to test the impact of reducing class size on student test scores. Over four years, teachers and classrooms across eighty schools were randomly assigned to classes of smaller sizes, the treatment group, or to a control group of regular sized classes. 
Students in small classes performed four percentage points better in test scores than those in the larger classes in the first year of the experiment and one percentage point better every year thereafter. Because similarly situated teachers and students were randomly assigned, we can infer that class size explains the improvement in test scores. By comparing two identical groups chosen at random, we can control for a whole range of factors that enable us to understand what is working and what is not. This is why many consider RCTs to be the gold standard of evidence.
The importance of RCTs was underscored with the awarding of the 2019 Nobel Prize for Economics to Michael Kremer, Abhijit Banerjee and Esther Duflo for their experimental work alleviating poverty.
For you, it will be important to be able to find the results of completed RCTs. A number of open repositories and evidence clearinghouses now share these studies in a variety of ways, often scoring studies to determine their credibility and sharing them systematically.
We share a list of these in the worksheets accompanying this video.
Before we move on, a note about the limits of RCTs.
The hierarchy that has emerged in evidence-based policymaking, with the RCT as top of the pyramid, can lead to other important evidentiary sources being overlooked. Promising ideas often comes from more varied sources and RCTs have serious limitations:
For a start, these studies can be slow. Experiments take time to conduct and often over a year or more to publish in a peer-reviewed journal. 
For example, in the 1990s, the US federal government did an experiment in housing policy by giving some families a rental subsidy if they moved from a higher to a lower poverty neighborhood. The results of the initial RCT found that "moving out of a disadvantaged, dangerous neighborhood into more affluent and safer areas does not have detectable impacts on economic outcomes four to seven years out." However, follow-up research a decade later revealed that these relocation programs had profound economic benefits for the children of the families who moved. A few extra years of data made all the difference.
Research funding is also too limited for randomized controlled trials to assess every innovation in every domain. 
Many effective innovators do not have the time, resources or know how to partner with academic researchers to conduct a study. 
Academic researchers will not conduct experiments where there is no grant funding as they need such funding to hire the PhDs and post-doctoral students to conduct the work with them.
And whereas RCTs answer the question, "Did it work?" they can sometimes be a "black box" when it comes to the question of "how it worked" or how satisfied people are. 
Furthermore, RCTs tend to test very only small and incremental changes. Sometimes we need to be radical and try bigger things than we can measure with an RCT. For example, it is nearly impossible to design RCTs to test innovative approaches to redesigning and rearranging organizations and institutions, such as the effect of an open innovation competition.
 So - we cannot be limited to choosing only solutions that have been evaluated using an RCT. 
Many promising entrepreneurial and innovative solutions are not studied in RCTs. For example, MIT-Solve describes itself as a marketplace for social impact innovation designed to identify lasting solutions from tech entrepreneurs for the world's most pressing problems. It catalogs hundreds of innovations in use around the world like Faircap, a chemical free water filter used in Syria and Mozambique, or WheeLog!, an application that enables individuals and local governments to share accessibility information in Tokyo.
So how to we find what else is out there?
Solutions for solving public problems come in many forms. 
These include traditional government abilities to tax, regulate, spend, and deliver public services.
But the public entrepreneur has an expanded toolkit of solutions.
Review these lists to see if there's a promising approach you had not considered. For more detail on these novel approaches, see our module on Expanding Your Policy Readiness.
Next let's move to explore how to scavenge for who else has tried what.
First, we explore documents. We can learn about policy ideas and associated research from academic journals, from collections of surveys and statistics, from the news, and from other publications.
1. Academic journals contain a multitude of qualitative and quantitative research.  To reduce the need for frequent searches, they also allow you to set up alerts to receive notifications about new publications.
2. Statistics and trends can provide helpful context to understand both the problem and potential solutions. For example, in a survey about big data, Pew Research found that three-quarters of U.S. adults say that governments should more carefully regulate what companies can do with customers' personal information.
3. A news search is the most obvious place to begin using an Internet search engine or a news database. Google News can help you search across a variety of publications and will allow you to set up an alert so that Google sends you the news stories relevant to your query at the frequency you want.
When reading popular news articles, we must take care as many journalists are unreliable reporters of the validity of scientific studies. For example, the Blueberry Association of North America has funded several studies that indicate that cognitive benefits may be found from eating blueberries. As a result, countless media outlets have published stories on the benefits of blueberries for preventing Alzheimer's, dementia and cancer. 
Stories that tout one food as a cure-all are the same as any story that claims any single intervention will fix education, reduce the cost of healthcare, create jobs and address climate change – unlikely to be true.
4. Governments publish literature that can provide expert analysis in a solution space. 
The National Academies and the Congressional Research Service publish reports that collect relevant sources of research and summarize policy solutions.
For example, the CRS report on federal child welfare policy offers a forty-page explainer about current statutes, agency programs and their funding. 
5. Organizations, including government agencies, think tanks, interest groups and NGOs, also frequently publish studies and reports, detailing successful interventions.
6. Finally, looking to other jurisdictions and their institutions can be a useful starting point.  For example, if you are thinking about a problem at the state level, look both to other states and to organizations that catalog what other states do. 
Remember that many of the organizations who create and collect publications on policy ideas are advocacy organizations. They may publish helpful and detailed white papers, beautifully formatted publications, websites and well-edited newsletters. But often they are not disinterested sources providing a neutral or evidence-backed overview of the options. They are pushing a position. As with any evidence, therefore, it is important to consider more than one source and to evaluate it critically.
The public entrepreneur should not just ask, "What solutions are out there?" but "Who is out there?" Informed people are the fastest and shortcut to learning what has been tried and what is working. 
You will want to create a map of organizations and knowledgeable individuals. 
The best contacts will not only provide helpful information but also connect you to other people and relevant documents. 
We can learn by talking to content experts, civil servants, social media actors, and academic scholars.
1. Content Experts: Identifying lists of relevant conference speakers, people on panels, and keynote speakers, is a great shortcut for finding experts, as is checking grantee lists from philanthropies funding related work. Combing through relevant documents for links and citations can lead to relevant experts.
2. Civil servants: Government employees from other states, as well as city and national governments can share their own experiences – successes and failures. These public servants should be a go-to resource for expertise about what is and what is not working.
3. Social media: About two-thirds of Americans say they, at least sometimes, get their news from social media. Twitter, Facebook and other platforms for user-generated content provide news in real-time - albeit not always reliable news. Because many organizations cannot afford the communications staffing needed to bring attention to their programs to broadcast media, many prefer to advertise their work on social media.
To make the task easier, consider subscribing to existing or creating new Twitter lists. A Twitter list is a curated group of Twitter accounts. You can compile a list of the best people on your topic and create a list to monitor relevant conversations. 
Identifying relevant hashtags can also be another excellent shortcut for finding people and content. When searching by hashtag, you need to know, for example, if #education or #edtech or #classroom will be the better way to learn about learning related interventions.
4. Academic Expert networks allow you to search for domain experts through databases that increasingly use data science and machine learning techniques to source experts from catalogs of publications and other sources.
Once we identify who we want to talk with, we must determine how and when to best contact them. 
Early in the project, it is good to consult people who will be good sources of additional information, as well as powerful and connected people who will open doors to others either directly, or by virtue of your known connection to them. You will want to make it easy for such people to introduce you to others by writing a draft of the letter you want them to forward.  
It is also a good idea to contact both friendly experts and those likely to object to your project in the early stages of your research. Especially in government, you will want to identify people who may feel disrespected if you do not inform them of your work, consult with them, or invite them to an early meeting or discussion. Contacting potential opponents early will help to reduce political risk, or the chance that they will impede the progress of your research.
Truly hostile sources who will never be won over should be dealt with later, once you have had time to build up your evidence base and marshal your supporters. You also do not want to give them the opportunity to oppose you sooner than you have to in your planning process.
In addition, very busy or important people should be interviewed late in the process, once you have strong knowledge about your subject. You do not want to risk doing a poor job of interviewing them, since you will only get one chance to do so.
We have discussed how to gather examples of innovative solutions.
Now how do we evaluate these solutions?
We will first discuss the benefit of systematic reviews, then discuss alternative approaches.
Systematic reviews can help us understand how strong the overall evidence is for a type of policy solution in a way that a single study can make challenging.
Systematic reviews of RCTs comprehensively assess studies in a field using transparent and reproducible criteria. 
Rather than cherry picking among studies for those that support the desired conclusion, a systematic review looks holistically at all available studies to make it possible to evaluate the strength of a given claim. 
The review team assesses:
1. The validity and relative reliability of studies.
2. The sample size and the methods employed to assess quality. 
3. Potential errors and bias in how a study was conducted. 
4. Whether the conclusions drawn by the analysis make sense. 
Finally, it assesses whether the results of a study can be generalized. 
The great advantage of these meta-reviews is that trained statisticians and subject matter experts do the evaluative work for you. The Cochrane Centre has long been respected for its systematic reviews in medicine.
There are now an increasing number of clearinghouses sharing and reviewing policy studies. The clearinghouse of clearinghouses is Results First, sponsored by Pew Charitable Trusts and the MacArthur Foundation.
Results First is an online resource that brings together information on the effectiveness of social policy programs from nine other national clearinghouses. It applies color-coding to the clearinghouses' distinct rating systems, creating a common language that enables users to quickly see where each program falls on a spectrum from negative impact to positive impact.
As we discussed previously, RCTs are considered the strongest type of causal evaluation and are generally given the most weight by clearinghouses or systematic review. In addition, many foundations now encourage an experimental study like an RCT in order to improve an investment's chances of success.
Of course non-RCT studies can provide useful information as well. For example, the MacArthur Foundation demands at least one external evaluation of outcomes to qualify for its $10 million economic opportunity challenge and non-randomized studies can count towards this requirement. The aforementioned Cochrane Centre also incorporates non-experimental evaluations into its systematic reviews.
Another way to evaluate the quality of evidence is exemplified by Britain's city of York, which measures the effectiveness of its programs using a method called Social Impact Return on Investments. This approach analyzes the anticipated return on investment for every dollar spent in terms of a program's stated social values and goals
Modern machine learning approaches can make it possible to assess more complex context and variables than can be assessed in an RCT. 
Thus, the presence or absence of an RCT should neither be definitive nor dispositive when you decide to adopt an approach. Many initiatives that are not the subject of a randomized trial have significant impact, while many interventions that are the subject of successful RCTs do not translate well from one jurisdiction to another. So keep in mind that correlation is not causation in the process of evaluating good solutions. 
To evaluate the types of non-traditional evidence we discussed previously, as well as non-experimental studies, you can consider leveraging collective intelligence to conduct and evaluate your field scan.
For example, in 2013, the UK's What Works Centre for Crime Reduction. Ran a pilot "Evidence Boot Camp" to engage police officers and staff in crowdsourcing evidence and identifying solutions that work. 
Each team sifted through an average of 1133 publications in order to arrive at a collection of about fifty relevant articles and build an initial evidence base.
You can use the Smarter Crowdsourcing and Wiki Survey methods and associated tools discussed in Module 4 in order to convene groups of experts online to identify and evaluate evidence. Just keep in mind that "experts" can comprise a very diverse bunch, including academics with quantitative or qualitative approaches, practitioners, stakeholders, community groups and entrepreneurs. Each of these has different skills and insights into what's working.
Finally, we do not judge the merits of evidence in a vacuum. We must know more about our context, or what some call the "support factors" to determine what will work in our own communities.
Remember our example of Tennessee's successful experiments to improve reading scores by reducing class size in the 1980s?
 In the 2000's, California sought to replicate its success. Not only did reducing class size fail to improve reading scores, it made things worse. 
What happened?
In Tennessee, the project involved only schools that had available space. In California, often there was not enough spare space, and it had to be taken from other programs. 
Tennessee had no shortage of qualified teachers to staff the smaller classes. But California had to hire an additional 12,000 teachers so quickly that many were unqualified. 
Tennessee's policy might have worked in California, but the support factors were not present.
To figure out what needs to be present for an intervention to work "here", you need to understand the supporting factors that made it work "there". Some scholars describe the solution as one ingredient in a cake that works with other ingredients to produce the desired effect. Without the supporting ingredients, the cake will not rise.
Again, we can apply collective intelligence approaches to assessing context and support factors. We can engage with the community we are serving to decide whether an intervention that worked "there" is appropriate for "here."  There is no hard and fast rule for success in this process. The entrepreneur and the community must exercise their collective judgment and wisdom to decide whether the factors needed for the intervention to be replicated are locally present, and whether the risk is worth taking. 
Deliberative dialogues can be one way to engage people in mining evidence for its relevance to their community. For example, the Jefferson Center in Minneapolis, Minnesota has developed a model, which promotes the use of "citizen juries" -- a random sample of citizens --  to deliberate on specific policy proposals.
The British Parliament takes a different approach to collaborative evaluation of evidence. In month-long online exercises known as "Evidence Checks," members of the public are invited to comment on the validity of evidence on which a policy is based via the Internet. The committee also presents specific questions and problems that it would like participants to address. This process allows a large and diverse group of people with relevant experience and expertise to identify gaps in research that require further review. 
Of course, assessing the relevance of evidence is not the only consideration. Next, we, will consider broader issues of political and logistical feasibility that must be considered when assessing whether to implement a given solution.